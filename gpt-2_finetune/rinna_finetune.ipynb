{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YXxmUS4M3Mg"
   },
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad7qW1ZsNCwC"
   },
   "outputs": [],
   "source": [
    "!pip install -e transformers\n",
    "!pip install datasets\n",
    "!pip install sentencepiece\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aVFSIzJO2oo",
    "outputId": "9aa711f4-aeac-41db-da9d-02b20e7caee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUeO6FgJNEqC"
   },
   "outputs": [],
   "source": [
    "train_file_path = '/content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/transformers-main/examples/pytorch/language-modeling/run_clm.py'\n",
    "model_name = 'rinna/japanese-gpt-1b'\n",
    "\n",
    "train_data = '/content/drive/MyDrive/rinna_testing/Corpus/all/4_categories_20000.txt'\n",
    "train_epochs = 5\n",
    "\n",
    "train_bs = 1\n",
    "\n",
    "val_data = '/content/drive/MyDrive/rinna_testing/Corpus/all/4_categories_20000.txt'\n",
    "val_bs = 1\n",
    "\n",
    "output_path = '/content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/Model/all/11_categories/train-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Af1hSY8DNILX",
    "outputId": "48852981-e3c0-4f42-9434-12a975e7c72f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsmuS5bUNIhI",
    "outputId": "df3ea64c-d177-4fbb-c466-3bdad1c0ca3a"
   },
   "outputs": [],
   "source": [
    "!python {train_file_path} \\\n",
    "    --overwrite_output_dir \\\n",
    "    --model_name_or_path={model_name} \\\n",
    "    --train_file={train_data} \\\n",
    "    --validation_file={val_data} \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --num_train_epochs={train_epochs} \\\n",
    "    --save_steps=10000 \\\n",
    "    --save_total_limit=3 \\\n",
    "    --per_device_train_batch_size={train_bs} \\\n",
    "    --per_device_eval_batch_size={val_bs} \\\n",
    "    --output_dir={output_path} \\\n",
    "    --use_fast_tokenizer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generated_str(output_data_list):\n",
    "    generated_str = \"\"\n",
    "    print(output_data_list)\n",
    "    for cur_text in output_data_list:\n",
    "        generated_texts = cur_text.split('</s>')[1:]\n",
    "        for txt in generated_texts:\n",
    "            #print(\"Generated Text : \",txt)\n",
    "            generated_str = generated_str.strip()+\" \" +txt.strip()\n",
    "            generated_str.strip()\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, AutoModelForCausalLM\n",
    "tokenizer_medium = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'/content/drive/MyDrive/rinna_testing/Model/all_11/train-2'\n",
    "max_len = 5\n",
    "model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "No_ofSentences = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "input_text = \"日本の冬：最高のスキー場、温泉などへのガイド\"\n",
    "textMax_len = 1000\n",
    "\n",
    "tokenized_input_ =  tokenizer_medium.encode(input_text, return_tensors=\"pt\")\n",
    "generated_output = model.generate(tokenized_input_, do_sample=True, max_length=textMax_len, num_return_sequences=No_ofSentences)\n",
    "\n",
    "generated_list = tokenizer_medium.batch_decode(generated_output)\n",
    "generated_str = get_generated_str(generated_list)\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(generated_str)\n",
    "print(duration)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "7bf549bcfbdd48dc6f984b1394fe292226f9ee0fe2edfef41a38f63dca90de25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
