<<<<<<< Updated upstream
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9721,"status":"ok","timestamp":1669012893424,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"Grwf_qpExalj","outputId":"f2817213-97b2-4b87-fe6c-316d6bfee376"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5189,"status":"ok","timestamp":1669012898610,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"_dihpG4pemT7","outputId":"7879a079-9faa-48ea-e402-09309b74a50e"},"outputs":[],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3538,"status":"ok","timestamp":1669013260710,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"r1-ME6ADT2lm"},"outputs":[],"source":["# import\n","import re\n","import json\n","import torch\n","import random\n","import pandas as pd\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, random_split\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n"]},{"cell_type":"markdown","metadata":{"id":"DRi2aNLSTslr"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1669013260711,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"2Q8JdyLwTqbj"},"outputs":[],"source":["# Dataset class\n","class BeautyDataset(Dataset):\n","    def __init__(self, txt_list, label_list, tokenizer, max_length):\n","        # define variables    \n","        self.input_ids = []\n","        self.attn_masks = []\n","        #self.labels = []\n","        \n","        # iterate through the dataset\n","        # truncate long content > 256\n","        for txt, label in zip(txt_list, label_list):\n","            txt= txt.replace(\"\\n\", \"\")\n","            txt_ = (txt[:256]) if len(txt) > 256 else txt\n","\n","            # prepare the text\n","            prep_txt = f'<s>Content: {txt_}\\nTitle: {label}</s>'\n","            # tokenize\n","            encodings_dict = tokenizer(prep_txt, truncation=True,\n","                                       max_length=max_length, padding=\"max_length\")\n","            # append to list\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","            #self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":408,"status":"ok","timestamp":1669013281145,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"DiXgVOxzYWjC"},"outputs":[],"source":["def read_content_title():\n","  import glob\n","\n","  path = r'all' # folder\n","  all_files = glob.glob(path + \"/*.csv\")\n","\n","  list_ = []\n","\n","  for filename in all_files:\n","    try:\n","      #print(filename)\n","      df_t = pd.read_csv(filename, index_col=None, header=None, skiprows=1, encoding='utf-8')\n","      list_.append(df_t)\n","    except:\n","      print(f\"reading error in{filename}\")\n","\n","\n","\n","  frame = pd.concat(list_, axis=0, ignore_index=True)\n","  print(f\"length of data frame: {len(frame)}\")\n","  return frame"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":500,"status":"ok","timestamp":1669013296390,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"yUfT0J7_YAcC"},"outputs":[],"source":["# Data load function\n","def load_beauty_dataset(tokenizer, random_seed = 1):\n","    # load dataset and sample.\n","    #df = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n","    df = read_content_title()\n","    df = df[[0, 1]]\n","    df.columns = ['content', 'title']\n","    df = df.sample(20000, random_state=1)\n","    \n","    max_length = max([len(tokenizer.encode(description)) for description in df['content']])\n","    print(\"Max length: {}\".format(max_length))\n","\n","    dataset = BeautyDataset(df['content'].tolist(), df['title'].tolist(), tokenizer, max_length=512)\n","    dataset.__getitem__(5)\n","\n","    \n","    train_size = int(0.9 * len(dataset))\n","    train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n","    print(len(dataset))\n","\n","    # return\n","    return train_dataset, val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8493,"status":"ok","timestamp":1669013308209,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"Ypo_dRLADD-t","outputId":"8da99e71-bd0b-4889-ad3d-f565656295a1"},"outputs":[],"source":["from transformers import T5Tokenizer, AutoModelForCausalLM, GPT2LMHeadModel\n","  \n","tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\", bos_token='<s>', eos_token='</s>', pad_token='<pad>')\n","\n","\n","model = GPT2LMHeadModel.from_pretrained(\"rinna/japanese-gpt2-medium\").cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1771,"status":"ok","timestamp":1669013317030,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"T4veFbFBxz54","outputId":"799d9792-cdd9-431b-b2fd-4373ed3aa93c"},"outputs":[],"source":["model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46129,"status":"ok","timestamp":1669013365818,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"vsCoyVnJV--E","outputId":"f0ab8a40-acb8-4f85-f600-6c89d8eab1ba"},"outputs":[],"source":["for trial_no in range(1):\n","  print(\"Loading dataset...\")\n","  train_dataset, val_dataset = load_beauty_dataset(tokenizer, trial_no)\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"D2TEfiLhzYEv","outputId":"f5ac1c7a-2e13-4b00-a81c-5712b2ffad5e"},"outputs":[],"source":["print(\"Start training...\")\n","training_args = TrainingArguments(output_dir=r'21-11-22-rinna-content-title', num_train_epochs=5, \n","                                logging_steps=100, load_best_model_at_end=True,\n","                                save_strategy='steps',\n","                                evaluation_strategy=\"steps\",\n","                                save_steps=1000,\n","                                per_device_train_batch_size=6, per_device_eval_batch_size=6,\n","                                learning_rate=0.1,\n","                                warmup_steps=1, weight_decay=0.01, logging_dir='logs')\n","\n","\n","trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset,\n","          eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n","                                                                'attention_mask': torch.stack([f[1] for f in data]),\n","                                                                'labels': torch.stack([f[0] for f in data])})\n","trainer.train()                                                  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8611,"status":"ok","timestamp":1668496068433,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"ltybeRh_WdvM","outputId":"19b6d8b8-ba77-4685-d2ec-dfed49fcd7aa"},"outputs":[],"source":["import os\n","\n","output_dir = '21-11-22-rinna-content-title/final'\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","\n","model_to_save = model.module if hasattr(model, 'module') else model\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9745,"status":"ok","timestamp":1668496278374,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"tT76TT3DIJB7","outputId":"58b3c030-c610-4c69-860f-7ad838006016"},"outputs":[],"source":["model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/few-shot-learning/18-11-22-rinna-content-title/final\").cuda()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3505,"status":"ok","timestamp":1668496507282,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"Hdl2A1H3gSTf","outputId":"c6f56cf3-5084-4572-c141-956e7070ea20"},"outputs":[],"source":["text = '【ブローチェ　アヴェダ】また、ピンクブラウンにはメリットが多いのも魅力の一つ。自分に似合う髪色が見つからないという方にとって魅力的なメリットがたくさんあります◎【ピンクブラウンのメリット】①光に当たった時の柔らかさと透明感 ②日本人の肌に馴染みのいい色味 ③パーソナルカラーのイエベさんもブルベさんも取り入れやすい色合い ここからはそんなピンクブラウンについて、さまざまな角度からおすすめヘアスタイルを紹介していきます。光に当たった時の柔らかさと透明感日本人の肌に馴染みのいい色味パーソナルカラーのイエベさんもブルベさんも取り入れやすい色合い'\n","prompt = f'Content: {text}\\nTitle:'\n","generated = tokenizer(f\"<s> {prompt}\", return_tensors=\"pt\").input_ids.cuda()\n","sample_outputs = model.generate(generated, do_sample=False, top_k=50, max_length=256, top_p=0.90, \n","            temperature=0, num_return_sequences=0).cuda()\n","pred_text = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n","           "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1668496507282,"user":{"displayName":"KHIN KHANT KHANT HLAING","userId":"10342000142729790877"},"user_tz":-390},"id":"OW5v8hZlIQYq","outputId":"f050d4d0-c81a-4fff-ce7f-3f3b09a45871"},"outputs":[],"source":["print(pred_text)"]},{"cell_type":"markdown","metadata":{"id":"RlUqOSY-fkSL"},"source":["ref: https://qiita.com/m__k/items/36875fedf8ad1842b729"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLVXKLimflMR"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOsUr504FXHLyYhAxXfRzj2","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 ('base')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.12"},"vscode":{"interpreter":{"hash":"ffdbdde1c7f3cb0c6e4302d47b8b69bbc9567b6e444b9944e0284485fba4246d"}}},"nbformat":4,"nbformat_minor":0}
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9721,
     "status": "ok",
     "timestamp": 1669012893424,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "Grwf_qpExalj",
    "outputId": "f2817213-97b2-4b87-fe6c-316d6bfee376"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5189,
     "status": "ok",
     "timestamp": 1669012898610,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "_dihpG4pemT7",
    "outputId": "7879a079-9faa-48ea-e402-09309b74a50e"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3538,
     "status": "ok",
     "timestamp": 1669013260710,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "r1-ME6ADT2lm"
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRi2aNLSTslr"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669013260711,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "2Q8JdyLwTqbj"
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class BeautyDataset(Dataset):\n",
    "    def __init__(self, txt_list, label_list, tokenizer, max_length):\n",
    "        # define variables    \n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        #self.labels = []\n",
    "        \n",
    "        # iterate through the dataset\n",
    "        # truncate long content > 256\n",
    "        for txt, label in zip(txt_list, label_list):\n",
    "            txt= txt.replace(\"\\n\", \"\")\n",
    "            txt_ = (txt[:256]) if len(txt) > 256 else txt\n",
    "\n",
    "            # prepare the text\n",
    "            prep_txt = f'<s>Content: {txt_}\\nTitle: {label}</s>'\n",
    "            # tokenize\n",
    "            encodings_dict = tokenizer(prep_txt, truncation=True,\n",
    "                                       max_length=max_length, padding=\"max_length\")\n",
    "            # append to list\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "            #self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1669013281145,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "DiXgVOxzYWjC"
   },
   "outputs": [],
   "source": [
    "def read_content_title():\n",
    "  import glob\n",
    "\n",
    "  path = r'all' # folder\n",
    "  all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "  list_ = []\n",
    "\n",
    "  for filename in all_files:\n",
    "    try:\n",
    "      #print(filename)\n",
    "      df_t = pd.read_csv(filename, index_col=None, header=None, skiprows=1, encoding='utf-8')\n",
    "      list_.append(df_t)\n",
    "    except:\n",
    "      print(f\"reading error in{filename}\")\n",
    "\n",
    "\n",
    "\n",
    "  frame = pd.concat(list_, axis=0, ignore_index=True)\n",
    "  print(f\"length of data frame: {len(frame)}\")\n",
    "  return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1669013296390,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "yUfT0J7_YAcC"
   },
   "outputs": [],
   "source": [
    "# Data load function\n",
    "def load_beauty_dataset(tokenizer, random_seed = 1):\n",
    "    # load dataset and sample.\n",
    "    #df = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n",
    "    df = read_content_title()\n",
    "    df = df[[0, 1]]\n",
    "    df.columns = ['content', 'title']\n",
    "    df = df.sample(20000, random_state=1)\n",
    "    \n",
    "    max_length = max([len(tokenizer.encode(description)) for description in df['content']])\n",
    "    print(\"Max length: {}\".format(max_length))\n",
    "\n",
    "    dataset = BeautyDataset(df['content'].tolist(), df['title'].tolist(), tokenizer, max_length=512)\n",
    "    dataset.__getitem__(5)\n",
    "\n",
    "    \n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "    print(len(dataset))\n",
    "\n",
    "    # return\n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8493,
     "status": "ok",
     "timestamp": 1669013308209,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "Ypo_dRLADD-t",
    "outputId": "8da99e71-bd0b-4889-ad3d-f565656295a1"
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, AutoModelForCausalLM, GPT2LMHeadModel\n",
    "  \n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\", bos_token='<s>', eos_token='</s>', pad_token='<pad>')\n",
    "\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"rinna/japanese-gpt2-medium\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1669013317030,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "T4veFbFBxz54",
    "outputId": "799d9792-cdd9-431b-b2fd-4373ed3aa93c"
   },
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46129,
     "status": "ok",
     "timestamp": 1669013365818,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "vsCoyVnJV--E",
    "outputId": "f0ab8a40-acb8-4f85-f600-6c89d8eab1ba"
   },
   "outputs": [],
   "source": [
    "for trial_no in range(1):\n",
    "  print(\"Loading dataset...\")\n",
    "  train_dataset, val_dataset = load_beauty_dataset(tokenizer, trial_no)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "D2TEfiLhzYEv",
    "outputId": "f5ac1c7a-2e13-4b00-a81c-5712b2ffad5e"
   },
   "outputs": [],
   "source": [
    "print(\"Start training...\")\n",
    "training_args = TrainingArguments(output_dir=r'21-11-22-rinna-content-title', num_train_epochs=5, \n",
    "                                logging_steps=100, load_best_model_at_end=True,\n",
    "                                save_strategy='steps',\n",
    "                                evaluation_strategy=\"steps\",\n",
    "                                save_steps=1000,\n",
    "                                per_device_train_batch_size=6, per_device_eval_batch_size=6,\n",
    "                                learning_rate=0.1,\n",
    "                                warmup_steps=1, weight_decay=0.01, logging_dir='logs')\n",
    "\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset,\n",
    "          eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n",
    "                                                                'attention_mask': torch.stack([f[1] for f in data]),\n",
    "                                                                'labels': torch.stack([f[0] for f in data])})\n",
    "trainer.train()                                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8611,
     "status": "ok",
     "timestamp": 1668496068433,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "ltybeRh_WdvM",
    "outputId": "19b6d8b8-ba77-4685-d2ec-dfed49fcd7aa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = '21-11-22-rinna-content-title/final'\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "\n",
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9745,
     "status": "ok",
     "timestamp": 1668496278374,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "tT76TT3DIJB7",
    "outputId": "58b3c030-c610-4c69-860f-7ad838006016"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/few-shot-learning/18-11-22-rinna-content-title/final\").cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3505,
     "status": "ok",
     "timestamp": 1668496507282,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "Hdl2A1H3gSTf",
    "outputId": "c6f56cf3-5084-4572-c141-956e7070ea20"
   },
   "outputs": [],
   "source": [
    "text = '【ブローチェ　アヴェダ】また、ピンクブラウンにはメリットが多いのも魅力の一つ。自分に似合う髪色が見つからないという方にとって魅力的なメリットがたくさんあります◎【ピンクブラウンのメリット】①光に当たった時の柔らかさと透明感 ②日本人の肌に馴染みのいい色味 ③パーソナルカラーのイエベさんもブルベさんも取り入れやすい色合い ここからはそんなピンクブラウンについて、さまざまな角度からおすすめヘアスタイルを紹介していきます。光に当たった時の柔らかさと透明感日本人の肌に馴染みのいい色味パーソナルカラーのイエベさんもブルベさんも取り入れやすい色合い'\n",
    "prompt = f'Content: {text}\\nTitle:'\n",
    "generated = tokenizer(f\"<s> {prompt}\", return_tensors=\"pt\").input_ids.cuda()\n",
    "sample_outputs = model.generate(generated, do_sample=False, top_k=50, max_length=256, top_p=0.90, \n",
    "            temperature=0, num_return_sequences=0).cuda()\n",
    "pred_text = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1668496507282,
     "user": {
      "displayName": "KHIN KHANT KHANT HLAING",
      "userId": "10342000142729790877"
     },
     "user_tz": -390
    },
    "id": "OW5v8hZlIQYq",
    "outputId": "f050d4d0-c81a-4fff-ce7f-3f3b09a45871"
   },
   "outputs": [],
   "source": [
    "print(pred_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlUqOSY-fkSL"
   },
   "source": [
    "ref: https://qiita.com/m__k/items/36875fedf8ad1842b729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kLVXKLimflMR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOsUr504FXHLyYhAxXfRzj2",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
>>>>>>> Stashed changes
