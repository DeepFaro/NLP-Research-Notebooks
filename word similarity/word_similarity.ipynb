{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word similarity measure with spaCy\n",
    "\n",
    "#### Install required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_word(nlp_model, w, words_vectors):\n",
    "    \"\"\"\n",
    "    Compares new word with those in the words vectors dictionary\n",
    "    \"\"\"\n",
    "    vec = nlp_model(w)\n",
    "    return {w1:vec.similarity(vec1) for w1,vec1 in words_vectors.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For English   \n",
    "#### Download english models : https://spacy.io/models/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load the language model\n",
    "en_nlp_model = spacy.load('en_core_web_md')\n",
    "\n",
    "# set based keyword list\n",
    "word_list = ['queen', 'beauty', 'reform', 'bar', 'car', 'drink', 'lesson music']\n",
    "word_list1 = [ 'travel', 'restaurant', 'architecture', 'massage']\n",
    "\n",
    "# convert the strings to spaCy Token objects\n",
    "tokens_ = {}\n",
    "for ww in word_list:\n",
    "  tokens_[ww] = (en_nlp_model(ww)[0])\n",
    "\n",
    "tokens_1 = {}\n",
    "for ww in word_list1:\n",
    "  tokens_1[ww] = (en_nlp_model(ww)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl :  {'queen': 0.4620418872631475, 'beauty': 0.3470903688146996, 'reform': -0.01668207995090511, 'bar': 0.19038626272144732, 'car': 0.22550734404683506, 'drink': 0.2563003838616516, 'lesson music': 0.13454798024404474}\n",
      "girl :  {'travel': 0.00431965427181635, 'restaurant': 0.15304958562159815, 'architecture': -0.030297284505522805, 'massage': 0.20896072402710156}\n"
     ]
    }
   ],
   "source": [
    "print('girl : ', compare_word(en_nlp_model, 'girl', tokens_))\n",
    "print('girl : ', compare_word(en_nlp_model, 'girl', tokens_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hair style :  {'queen': 0.2138813478817842, 'beauty': 0.5440184398678954, 'reform': 0.05707112084494526, 'bar': 0.21484520763149056, 'car': 0.1840519490356011, 'drink': 0.21416462322399799, 'lesson music': 0.11556897228343867}\n",
      "hair style :  {'travel': 0.12237028136630919, 'restaurant': 0.20786229246414947, 'architecture': 0.3594509572861326, 'massage': 0.35209446729072374}\n"
     ]
    }
   ],
   "source": [
    "print('hair style : ', compare_word(en_nlp_model, 'hair style', tokens_))\n",
    "print('hair style : ', compare_word(en_nlp_model, 'hair style', tokens_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Japanese\n",
    "#### Download english models : https://spacy.io/models/ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download ja_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load the language model\n",
    "ja_nlp_model = spacy.load('ja_core_news_lg')\n",
    "\n",
    "\n",
    "\n",
    "# set based keyword list\n",
    "word_list = ['女王', '美容', '改革', 'バー', '車', '飲み物', 'レッスン音楽']\n",
    "            #['Queen', 'Beauty', 'Reform', 'Bar', 'Car', 'Drink', 'Lesson Music']\n",
    "word_list1 = [ '旅行', 'レストラン', '建築', 'マッサージ']\n",
    "            #[ 'Travel', 'Restaurant', 'Architecture', 'Massage']\n",
    "\n",
    "# convert the strings to spaCy Token objects\n",
    "tokens_ = {}\n",
    "for ww in word_list:\n",
    "  tokens_[ww] = (ja_nlp_model(ww)[0])\n",
    "\n",
    "tokens_1 = {}\n",
    "for ww in word_list1:\n",
    "  tokens_1[ww] = (ja_nlp_model(ww)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast food :  {'女王': 0.07120987830348414, '美容': 0.2375892347426994, '改革': 0.1336707593366052, 'バー': 0.21089440233405077, '車': 0.15480723803406446, '飲み物': 0.3816738421577496, 'レッスン音楽': 0.1301331524993787}\n",
      "ファストフード :  {'旅行': 0.17283721771662436, 'レストラン': 0.412974824210537, '建築': 0.12923340154345833, 'マッサージ': 0.1876916523216345}\n"
     ]
    }
   ],
   "source": [
    "print('Fast food : ', compare_word(ja_nlp_model, 'ファストフード', tokens_))\n",
    "print('ファストフード : ', compare_word(ja_nlp_model, 'ファストフード', tokens_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hair style :  {'女王': 0.11064131229204496, '美容': 0.4185264741302789, '改革': 0.03756975943847968, 'バー': 0.14951228099306335, '車': 0.10908257623830947, '飲み物': 0.20861923996778534, 'レッスン音楽': 0.20778039978945873}\n",
      "ヘアスタイル :  {'旅行': 0.16705126851787047, 'レストラン': 0.21044082423393054, '建築': 0.17307159712980988, 'マッサージ': 0.28862216560994336}\n"
     ]
    }
   ],
   "source": [
    "print('hair style : ', compare_word(ja_nlp_model, 'ヘアスタイル', tokens_))\n",
    "print('ヘアスタイル : ', compare_word(ja_nlp_model, 'ヘアスタイル', tokens_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Most Similar Words......\n",
      "('drinks', 0.8851481080055237)\n",
      "('beer', 0.8182137608528137)\n",
      "('drinking', 0.750116229057312)\n",
      "('liquor', 0.7198688983917236)\n",
      "('bottled', 0.7179968953132629)\n",
      "('soda', 0.71770179271698)\n",
      "('beverages', 0.7114107608795166)\n",
      "('bottle', 0.7083661556243896)\n",
      "('drank', 0.7047054767608643)\n",
      "('coffee', 0.699092447757721)\n",
      "('beverage', 0.6927410364151001)\n",
      "('eat', 0.6849386096000671)\n",
      "('alcohol', 0.6841266751289368)\n",
      "('wine', 0.6808558106422424)\n",
      "('tea', 0.6683973670005798)\n",
      "('milk', 0.66713547706604)\n",
      "('snack', 0.6655228137969971)\n",
      "('alcoholic', 0.6637224555015564)\n",
      "('bottles', 0.6606711149215698)\n",
      "('vodka', 0.6571992635726929)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-100\")  \n",
    "bests = model.most_similar([\"drink\"], topn= 20)\n",
    "print(\"......Most Similar Words......\")\n",
    "for best in bests:\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Most Similar Words......\n",
      "[('beautiful', 0.6740165948867798), ('fashion', 0.6238462328910828), ('glamour', 0.6215600967407227), ('nature', 0.609063446521759), ('love', 0.6026946902275085)]\n"
     ]
    }
   ],
   "source": [
    "bests = model.most_similar([\"beauty\"], topn= 5)\n",
    "print(\"......Most Similar Words......\")\n",
    "print(bests)\n",
    "\n",
    "tokens_2 = {}\n",
    "\n",
    "for best in bests:\n",
    "    \n",
    "    tokens_2[best[0]] = (en_nlp_model(best[0])[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hair style :  {'beautiful': 0.49262654504701126, 'fashion': 0.5497506854341697, 'glamour': 0.4657121984238619, 'nature': 0.38719293301649566, 'love': 0.34706353199867246}\n"
     ]
    }
   ],
   "source": [
    "print('hair style : ', compare_word(en_nlp_model, 'hair style', tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......Most Similar Words......\n",
      "[('building', 0.7728806138038635), ('projects', 0.7253748774528503), ('industrial', 0.7133155465126038), ('built', 0.7087695002555847), ('project', 0.7039004564285278)]\n"
     ]
    }
   ],
   "source": [
    "bests = model.most_similar([\"construction\"], topn= 5)\n",
    "print(\"......Most Similar Words......\")\n",
    "print(bests)\n",
    "\n",
    "tokens_3 = {}\n",
    "\n",
    "for best in bests:\n",
    "    \n",
    "    tokens_3[best[0]] = (en_nlp_model(best[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hair style :  {'building': 0.18545111781117804, 'projects': 0.1859823358533846, 'industrial': 0.17800051018304502, 'built': 0.09773349029991571, 'project': 0.14033476156478736}\n"
     ]
    }
   ],
   "source": [
    "print('hair style : ', compare_word(en_nlp_model, 'hair style', tokens_3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84e0bb0f00aa32ad0c8860aa2a23ee550c90ac42a454942d75bec40d4ae650b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
